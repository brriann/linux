###
### Ch. 4 Process Abstraction
###

process - abstraction of running program
CPU virtualization
time/space sharing

machine state of a process
-memory/address space
-registers
--PC program counter / IP instruction pointer
--stack pointer/frame pointer, function params, local vars, return addresses
-I/O information, persistent storage, open files

Process API
create, destroy, wait, status, misc control

Process Creation
-load code/static data from disk into memory
-allocate memory for run-time stack and heap
-I/O setup
-jump to main(), CONTROL OF CPU GIVEN TO PROCESS

Process states
running, ready, blocked
(scheduling/descheduling)

Process List of an OS
-register context of a stopped process

###
### Ch. 5 Process API
###

system calls

fork()
- almost exact copy child process created

exec()
- run other commands in a child process
-exec family of commands

wait()
-parent process waits for child to complete

fork & exec
-splitting them allows Unix shell to run code after fork but before exec
--environment of soon-to-be-run code can be altered

pipe()
- connect two processes, stdOutA = stdInB

kill()
- send SIGNALS to a process (to interrupt/stop)

###
### Ch. 6 - Mechanism, Limited Direct Execution
###

time sharing to virtualize CPU
processor modes - user vs kernel
system calls
"trapping into" kernel and "return from trap" back into user mode process
kernel stack

switching between processes
cooperative - OS regains control during system calls
non-coop : OS takes control on timer interrupts

context switch: OS saves register values for current process onto kernel stack

###
### Ch. 7 - Scheduling Intro
###

scheduling policies
workload assumptions
scheduling metrics
    turnaround time
    fairness
        (Jain's Fairness Index)

FIFO / FCFS
    neg: convoy effect

SJF (shortest job first)
    (job length is not usually known)

STCF (shortest time to completion first)
    preemptive SJF (preempt = stop job A, run job B, continue job A later)

scheduling metrics part 2
    response time

Round Robin
    run jobs for a time slice, then switch
    amortize cost of switching with longer slices

TRADEOFF:
Fair & good response time vs Unfair & good turnaround time

Overlap operations with I/O --- run Process B while Process A is waiting for I/O

predict future using recent past: multi-level feedback queue
